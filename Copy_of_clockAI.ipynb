{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of clockAI.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkong0414/Deep-Learning-Projects/blob/master/Copy_of_clockAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtPUY1vRJLsW",
        "colab_type": "code",
        "outputId": "a70004f9-760b-4830-e025-d387d4ae1198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#importing library\n",
        "\n",
        "import keras\n",
        "import os, shutil\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#use this when you use google colab only!\n",
        "from google.colab import files, drive\n",
        "import glob\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import pathlib\n",
        "\n",
        "from __future__ import absolute_import, division, print_function\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhK4eWmx_pHn",
        "colab_type": "text"
      },
      "source": [
        "Created by: Patrick Kong, Cody Hawkings\n",
        "                \n",
        "    clockAI project:\n",
        "    \n",
        "    This clock ai would aim to use computervision in order to read a clock's time.\n",
        "    It would be able to read digital and more importantly analog clocks.\n",
        "    \n",
        "    We will be using google colab for this project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbtLVrq20z9n",
        "colab_type": "text"
      },
      "source": [
        "###Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkSE-t5P3uXT",
        "colab_type": "code",
        "outputId": "21b24823-947c-477c-ea00-4e6203870e30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "#to import multiple files into google colab we first need to mount google drive\n",
        "#so that we can make directory calls to our photos and CSV files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3Rc6P1IViSg",
        "colab_type": "text"
      },
      "source": [
        "####A quick check of the files in the directory to see if the drive mounted correctly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZthwKK6M30vt",
        "colab_type": "code",
        "outputId": "4c9d5d2e-8775-4ca4-9acc-24428cc89924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "!ls \"/content/drive/My Drive/Colab Notebooks/Clocks\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'All Clocks.zip'   temp\t\t     test_digital\t   test_val_digital.csv\n",
            "'Analog Clock'\t   test_analog\t     test_digital.csv\t   test_validation.csv\n",
            "'Digital Clock'    test_analog.csv   test_val_analog.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7ib78dC1J0i",
        "colab_type": "text"
      },
      "source": [
        "####Directory Calls to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gIa51Tu8Mrl",
        "colab_type": "code",
        "outputId": "d4481b81-1204-488d-893d-bc5c53eb52e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "#file directory for analog\n",
        "base_A_dir = \"/content/drive/My Drive/Colab Notebooks/Clocks/Analog Clock/train\"\n",
        "\n",
        "#file directory for digital\n",
        "base_D_dir = \"/content/drive/My Drive/Colab Notebooks/Clocks/Digital Clock/train\"\n",
        "\n",
        "#file directory for target (labels)\n",
        "base_LA_dir = \"/content/drive/My Drive/Colab Notebooks/Clocks/test_val_analog.csv\"\n",
        "base_LD_dir = \"/content/drive/My Drive/Colab Notebooks/Clocks/test_val_digital.csv\"\n",
        "\n",
        "\n",
        "#open files from drive mount in google colab for correct picture names and lables\n",
        "file_csv = open(base_LA_dir, 'r')\n",
        "file2_csv = open(base_LD_dir, 'r')\n",
        "\n",
        "\n",
        "#first we must go through the file and then split the information\n",
        "#we then remove any unwanted fluff so that we are only left with \n",
        "#the filename and the picture label\n",
        "#the filename will later be used to be joined with the correct directory\n",
        "#so that we can open up pictures in order\n",
        "train_A_labels = []\n",
        "train_A_filenames = []\n",
        "text_A = []\n",
        "\n",
        "for files in file_csv:\n",
        "  text_A = files.split( \",\" )\n",
        "  train_A_labels.append( text_A[1].strip( '\\n' ) )\n",
        "  train_A_filenames.append( text_A[0].strip( '\\ufeff' ) )\n",
        "#print( train_A_labels )\n",
        "# print( train_A_filenames )\n",
        "\n",
        "\n",
        "\n",
        "train_D_labels = []\n",
        "train_D_filenames = []\n",
        "text_D = []\n",
        "\n",
        "for files in file2_csv:\n",
        "  text_D = files.split( \",\" )\n",
        "  train_D_labels.append( text_D[1].strip( '\\n' ) )\n",
        "  train_D_filenames.append( text_D[0].strip( '\\ufeff' ) )\n",
        "#print( train_D_labels )\n",
        "#print( train_D_filenames )\n",
        "\n",
        "\n",
        "#Now that the filenames are in correct order we will append the \n",
        "#names of the pictures to their respective directory folder\n",
        "\n",
        "temp2 = []\n",
        "image_analog = []\n",
        "\n",
        "for items in train_A_filenames:\n",
        "  temp2 = os.path.join( base_A_dir, items )\n",
        "  image_analog.append( temp2 )\n",
        "\n",
        "print( image_analog[0] )\n",
        "\n",
        "temp3 = []\n",
        "image_digital = []\n",
        "\n",
        "for item in train_D_filenames:\n",
        "  temp3 = os.path.join( base_D_dir, item )\n",
        "  image_digital.append( temp3 )\n",
        "\n",
        "#print( image_digital[ : ] )\n",
        "\n",
        "#as a sanity check we print out everything to make sure we are getting the \n",
        "#correct files in the correct order and to make sure that the filenames\n",
        "#appended correctly with the directory paths\n",
        "\n",
        "# AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "\n",
        "# x_input = tf.zeros( [ 720, 100, 100, 3], dtype = 'float32')\n",
        "\n",
        "# def preprocess_image(image):\n",
        "#   image = tf.image.decode_jpeg(image, channels=3)\n",
        "#   image = tf.image.resize(image, [100, 100])\n",
        "#   image /= 255.0  # normalize to [0,1] range\n",
        "#   return image\n",
        "\n",
        "# def load_and_preprocess_image(path):\n",
        "#   image = tf.read_file(path)\n",
        "#   x_input = preprocess_image( image )\n",
        "#   return preprocess_image(image)\n",
        "\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.figure(figsize=(8,8))\n",
        "# for n,image in enumerate( train_A_filenames.take(2)):\n",
        "#   plt.subplot(2,2,n+1)\n",
        "#   plt.imshow(image)\n",
        "#   plt.grid(True)\n",
        "#   plt.xticks([])\n",
        "#   plt.yticks([])\n",
        "#   plt.show()\n",
        "  \n",
        "# plt.figure( figsize = ( 8, 8 ) )\n",
        "# for n, image in enumerate( train_D_filenames.take( 2 ) ):\n",
        "#   plt.subplot( 2, 2, n+1 )\n",
        "#   plt.imshow( image )\n",
        "#   plt.grid( True )\n",
        "#   plt.xticks( [] )\n",
        "#   plt.yticks( [] )\n",
        "#   plt.show()\n",
        "  \n",
        "time = []\n",
        "timeL = []\n",
        "theta = np.zeros( ( 720, 2 ), dtype = 'float64' )\n",
        "radius = np.zeros( ( 720, 2 ), dtype = 'float64' )\n",
        "annotate_Hour = np.zeros( ( 720, 2 ), dtype = 'float64' )\n",
        "annotate_Min = np.zeros( ( 720, 2 ), dtype = 'float64' )\n",
        "\n",
        "hour = 0.0\n",
        "minute = 0.0\n",
        "\n",
        "#this will read from the csv labels and calculate the appropriate theta\n",
        "#for the minute hand\n",
        "  \n",
        "#this will read the label and calculate the theta for the\n",
        "#hour hand now\n",
        "  \n",
        "for i in range( len( train_A_labels ) ):\n",
        "    \n",
        "  time =  train_A_labels[ i ].split( ':' )\n",
        "  hour = int( time[ 0 ] )\n",
        "  minute = int( time[ 1 ] )\n",
        "  \n",
        "  annotate_Hour[ i ][ 1 ] = float( 0.5 * minute )\n",
        "  annotate_Hour[ i ][ 0 ] = 2\n",
        "  annotate_Min[ i ][ 1 ] = float( 6 * minute )\n",
        "  annotate_Min[ i ][ 0 ] = 4\n",
        "  \n",
        "  \n",
        "  timeL.append( str( time[ 0 ] + time[ 1 ] ) )\n",
        "  \n",
        "#this will stack theta in a 720 x 1 x 2 format\n",
        "#printing output of both theta and radius\n",
        "print( timeL[ :10 ] )\n",
        "\n",
        "print( \"Hour annotations: \\n\" )\n",
        "print( annotate_Hour[ :5 ] )\n",
        "print( \"Minute annotations: \\n\" )\n",
        "print( annotate_Min[ :5 ] )\n",
        "  \n",
        "\n",
        "\n",
        "# img_path = image_analog[0]\n",
        "# img_path\n",
        "\n",
        "# img_raw = tf.read_file(img_path)\n",
        "# print(repr(img_raw))\n",
        "\n",
        "# img_tensor = tf.image.decode_image(img_raw)\n",
        "\n",
        "# print(img_tensor.shape)\n",
        "# print(img_tensor.dtype)\n",
        "\n",
        "# img_final = tf.image.resize_images(img_tensor, [150 , 150])\n",
        "# img_final = img_final/255.0\n",
        "# print(img_final.shape)\n",
        "# print(img_final.numpy().min())\n",
        "# print(img_final.numpy().max())\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Clocks/Analog Clock/train/pic_1.JPG\n",
            "['1200', '1201', '1202', '1203', '1204', '1205', '1206', '1207', '1208', '1209']\n",
            "Hour annotations: \n",
            "\n",
            "[[2.  0. ]\n",
            " [2.  0.5]\n",
            " [2.  1. ]\n",
            " [2.  1.5]\n",
            " [2.  2. ]]\n",
            "Minute annotations: \n",
            "\n",
            "[[ 4.  0.]\n",
            " [ 4.  6.]\n",
            " [ 4. 12.]\n",
            " [ 4. 18.]\n",
            " [ 4. 24.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEBXxOf7W0Os",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_to_index = dict((name, index) for index, name in enumerate(timeL))\n",
        "list_values = [ v for v in label_to_index.values() ]\n",
        "list_values\n",
        "y_output = keras.utils.to_categorical(list_values, num_classes = 720)\n",
        "print( y_output[0] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_3hm_SMt-Qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#puts everything into a (720, 100, 100, 3) 4d tensor\n",
        "imgs = []\n",
        "for images in image_analog:\n",
        "  img = image.load_img( images, target_size =( 100, 100 )  )\n",
        "  image_tensor = image.img_to_array( img )\n",
        "  image_tensor = np.expand_dims( image_tensor, axis = 0 )\n",
        "  image_tensor /= 255.0\n",
        "  imgs.append(image_tensor)\n",
        "  \n",
        "#imgs = np.concatenate(imgs, axis = 0)\n",
        "print( imgs.shape )\n",
        "\n",
        "plt.imshow( imgs[0] )\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTLWX085ueGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print( imgs.shape )\n",
        "print( annotate_Hour.shape )\n",
        "print( annotate_Min.shape )\n",
        "\n",
        "x_input = tf.Tensor( [ imgs, annotate_Hour, annotate_Min ], [ 720, 100, 100, 3, 2, 2 ], dtype = ( 'float32', 'float64', 'float64' ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8Jj71huf_iZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_to_index = dict((name, index) for index, name in enumerate(timeL))\n",
        "list_values = [ v for v in label_to_index.values() ]\n",
        "list_values\n",
        "y_output = keras.utils.to_categorical(list_values, num_classes = 720)\n",
        "print( y_output[0] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQr8A2OqBmcs",
        "colab_type": "text"
      },
      "source": [
        "double checking length of the image after the resizing operation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFwBZBxWDhfv",
        "colab_type": "text"
      },
      "source": [
        "visualizing input in an array format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9KXZu5ZB4OI",
        "colab_type": "text"
      },
      "source": [
        "printing length of image d after the resizing operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocZN1E8RBYeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 4\n",
        "num_val_samples = sum([len(image_analog), len(image_digital)]) \n",
        "num_epochs = 100\n",
        "num_scores = []\n",
        "\n",
        "for i in range( k ):\n",
        "  print( 'processing fold #', i )\n",
        "  val_data = images[ i * num_val_samples: (i + 1) * num_val_samples ]\n",
        "  val_targets = train_targets[ i * num_val_samples: (i + 1) * num_val_samples ]\n",
        "  \n",
        "#   partial_train_data = np.concatenate(\n",
        "#     [ train_data[ :i * num_val_samples ],\n",
        "#      train_data[ ( i + 1 ) * num_val_samples: ] ],\n",
        "#     axis = 0 )\n",
        "  \n",
        "#   partial_train_targets = np.concatenate(\n",
        "#     [ train_targets[ :i * num_val_samples ],\n",
        "#      train_targets[ ( i + 1 ) * num_val_samples: ] ],\n",
        "#     axis = 0 )\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atjfV07JDRyb",
        "colab_type": "text"
      },
      "source": [
        "This is the k folding snippet we'll use to get our split our training and validation data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaWlpAEP85gK",
        "colab_type": "text"
      },
      "source": [
        "Sanity test for the files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgn0IQGxJLsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data gen\n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "#functions\n",
        "\n",
        "def annotate_theta( img, labels ):\n",
        "  #this will be a series of characters read from a label\n",
        "\n",
        "  time = []\n",
        "  theta = []\n",
        "  radius = []\n",
        "  hour = 0\n",
        "  minute = 0\n",
        "  \n",
        "  \n",
        "  #this will read from the csv labels and calculate the appropriate theta\n",
        "  #for the minute hand\n",
        "  \n",
        "  #this will read the label and calculate the theta for the\n",
        "  #hour hand now\n",
        "  \n",
        "  for i in range( len( labels ) ):\n",
        "    \n",
        "    time = labels[ i ].split( ':' )\n",
        "    print( time )\n",
        "    hour = int( time[ 0 ] )\n",
        "    minute = int( time[ 1 ] )\n",
        "    radius[ 0 ] = 2\n",
        "    radius[ 1 ] = 4\n",
        "    theta[ 0 ] = ( 0.5 * minute )\n",
        "    theta[ 1 ] = ( 6 * minute )\n",
        "  \n",
        "  return radius, theta\n",
        "  \n",
        "\n",
        "def load_dataset(img, labels):\n",
        "  X = []\n",
        "  \n",
        "  #once we annotated radius and theta into r and t\n",
        "  #we will load it into a format of:\n",
        "  #dataset = [ img, [ r(hour), r(minute) ], [t(hour), t(minute) ] ]\n",
        "  \n",
        "  for i in range( len( img ) ):\n",
        "    r, t = annotate_theta( img[ i ], labels[ i ] )\n",
        "    print( r )\n",
        "    print( t )\n",
        "    X.append( img[i] )\n",
        "    X.append( r )\n",
        "    X.append( t )\n",
        "  \n",
        "  return X\n",
        "\n",
        "\n",
        "def residual_unit( inputs, filters, kernel, drop_out = 0.0, pooling = False ):\n",
        "  res = inputs\n",
        "  \n",
        "  if pooling == True:\n",
        "    res = conv2D( filters, kernel_size = 1, strides = ( 2, 2) )\n",
        "    inputs = MaxPooling2d( pool_size = ( 2, 2 ) )\n",
        "    \n",
        "  inputs = BatchNormalization()( inputs )\n",
        "  inputs = conv2D( filters, kernel, padding = 'same' )( inputs )\n",
        "  inputs = activation( \"relu\" )( inputs )\n",
        "  inputs = Dropout( drop_out )( inputs )\n",
        "  inputs = BatchNormalization( inputs )\n",
        "  inputs = conv2D( filters, kernel, padding = 'same' )( inputs )\n",
        "  inputs = activation( \"relu\" )( inputs )\n",
        "  \n",
        "  inputs = keras.layers.add( [ inputs, res ] )\n",
        "  \n",
        "  return inputs\n",
        "\n",
        "#main function\n",
        "\n",
        "\n",
        "#using callback to save a clock AI on best validation.\n",
        "#model.save('clock_ai_0.1.h5')\n",
        "\n",
        "inputs = residual_unit( inputs, 32, 3 )\n",
        "inputs = residual_unit( inputs, 32, 3 )\n",
        "\n",
        "inputs = residual_unit( inputs, 64, 3, 0.0, True )\n",
        "inputs = residual_unit( inputs, 64, 3 )\n",
        "\n",
        "inputs = residual_unit( inputs, 128, 3, 0.0, True )\n",
        "inputs = residual_unit( inputs, 128, 3 )\n",
        "\n",
        "inputs = BatchNormalization()( inputs )\n",
        "inputs = conv2D( 256, 3 )( inputs )\n",
        "inputs = activation( \"relu\" )( inputs )\n",
        "\n",
        "inputs = Flatten()\n",
        "inputs = Dense( 720 )\n",
        "inputs = activation( \"softmax\" )\n",
        "\n",
        "model.compile(optimizer = 'adam', \n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit( x_input , y_output, epochs=1, batch_size = 10, validation_data=(x_val, y_val) )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLurvC5Y8sut",
        "colab_type": "text"
      },
      "source": [
        "Gameplan is to use polar coordinates in order to give an additional feature to the learning model during training.\n",
        "\n",
        "Initially considered using pixels to calculate theta since arctan( y / x ) will give us the angle of the clock hand.\n",
        "However, since the pixels were blurry compounded by the fact that the conditions to make theta happen is complex, an alternative was considered.\n",
        "\n",
        "Rather than use X and Y to calculate theta, the idea is then to use degree of 360 and divide by units of 60 ( which represent the minutes ). This gives us 6 degrees of movement per ***\"minute\"***.\n",
        "\n",
        "For the ***\"Hour\"*** hand we know that the hand moves 5 minute units to move to the next hour. 5 * 6 gives us 30 degrees per hour, so if we take 30 degree /60 minutes we get 0.5 degrees/minute.\n",
        "\n",
        "Same idea will be applied to the hour-hand cause this would be the one that gives the model problem since the hour-hand moves as the minute hand moves and makes things a little harder to do for the hour identification.\n",
        "\n",
        "( 4/29/19 )\n",
        "\n",
        "*added k folding so we can get our training and validation split accordingly for the small sample size\n",
        "\n",
        "*added residual unit function which will allow us to make residual units with dropout and pooling capabilities\n",
        "\n",
        "*added annotation function which will generate the other portion of input the network will be using to learn\n",
        "\n",
        "*Data generator has been added but hasn't been customized to work with this problem\n",
        "\n"
      ]
    }
  ]
}