{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of clockAI.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkong0414/Deep-Learning-Projects/blob/master/Copy_of_clockAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtPUY1vRJLsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing library\n",
        "\n",
        "import keras\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "import os, shutil\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#use this when you use google colab only!\n",
        "from google.colab import files, drive\n",
        "import glob\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import pathlib\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhK4eWmx_pHn",
        "colab_type": "text"
      },
      "source": [
        "Created by: Patrick Kong, Cody Hawkings\n",
        "                \n",
        "    clockAI project:\n",
        "    \n",
        "    This clock ai would aim to use computervision in order to read a clock's time.\n",
        "    It would be able to read digital and more importantly analog clocks.\n",
        "    \n",
        "    We will be using google colab for this project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbtLVrq20z9n",
        "colab_type": "text"
      },
      "source": [
        "###Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkSE-t5P3uXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to import multiple files into google colab we first need to mount google drive\n",
        "#so that we can make directory calls to our photos and CSV files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3Rc6P1IViSg",
        "colab_type": "text"
      },
      "source": [
        "####A quick check of the files in the directory to see if the drive mounted correctly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZthwKK6M30vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls \"/content/drive/My Drive/Colab Notebooks/Clocks\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7ib78dC1J0i",
        "colab_type": "text"
      },
      "source": [
        "####Directory Calls to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gIa51Tu8Mrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#file directory for analog\n",
        "base_A_dir = \"/content/drive/My Drive/Colab Notebooks/Clocks/Analog Clock/train\"\n",
        "\n",
        "#file directory for digital\n",
        "base_D_dir = \"/content/drive/My Drive/Colab Notebooks/Clocks/Digital Clock/train\"\n",
        "\n",
        "#file directory for target (labels)\n",
        "base_LA_dir = \"/content/drive/My Drive/Colab Notebooks/Clocks/test_val_analog.csv\"\n",
        "base_LD_dir = \"/content/drive/My Drive/Colab Notebooks/Clocks/test_val_digital.csv\"\n",
        "\n",
        "\n",
        "#open files from drive mount in google colab for correct picture names and lables\n",
        "file_csv = open(base_LA_dir, 'r')\n",
        "file2_csv = open(base_LD_dir, 'r')\n",
        "\n",
        "\n",
        "#first we must go through the file and then split the information\n",
        "#we then remove any unwanted fluff so that we are only left with \n",
        "#the filename and the picture label\n",
        "#the filename will later be used to be joined with the correct directory\n",
        "#so that we can open up pictures in order\n",
        "train_A_labels = []\n",
        "train_A_filenames = []\n",
        "text_A = []\n",
        "\n",
        "for files in file_csv:\n",
        "  text_A = files.split( \",\" )\n",
        "  train_A_labels.append( text_A[1].strip( '\\n' ) )\n",
        "  train_A_filenames.append( text_A[0].strip( '\\ufeff' ) )\n",
        "print( train_A_labels )\n",
        "print( train_A_filenames )\n",
        "\n",
        "\n",
        "\n",
        "train_D_labels = []\n",
        "train_D_filenames = []\n",
        "text_D = []\n",
        "for files in file2_csv:\n",
        "  text_D = files.split( \",\" )\n",
        "  train_D_labels.append( text_D[1].strip( '\\n' ) )\n",
        "  train_D_filenames.append( text_D[0].strip( '\\ufeff' ) )\n",
        "# print( train_D_labels )\n",
        "# print( train_D_filenames )\n",
        "\n",
        "\n",
        "                                                                                      # #Now that the filenames are in correct order we will append the \n",
        "                                                                                      # #names of the pictures to their respective directory folder\n",
        "\n",
        "temp2 = []\n",
        "image_analog = []\n",
        "\n",
        "for items in train_A_filenames:\n",
        "  temp2 = os.path.join( base_A_dir, items )\n",
        "  image_analog.append( temp2 )\n",
        "\n",
        "print( image_analog )\n",
        "\n",
        "temp3 = []\n",
        "image_digital = []\n",
        "for item in train_D_filenames:\n",
        "  temp3 = os.path.join( base_D_dir, item )\n",
        "  image_digital.append( temp3 )\n",
        "\n",
        "# print( image_digital )\n",
        "\n",
        "\n",
        "                                                                                      \n",
        "#as a sanity check we print out everything to make sure we are getting the \n",
        "#correct files in the correct order and to make sure that the filenames\n",
        "#appended correctly with the directory paths\n",
        "\n",
        "                                                                                      # AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "\n",
        "                                                                                      # x_input = tf.zeros( [ 720, 100, 100, 3], dtype = 'float32')\n",
        "\n",
        "                                                                                      # def preprocess_image(image):\n",
        "                                                                                      #   image = tf.image.decode_jpeg(image, channels=3)\n",
        "                                                                                      #   image = tf.image.resize(image, [100, 100])\n",
        "                                                                                      #   image /= 255.0  # normalize to [0,1] range\n",
        "                                                                                      #   return image\n",
        "\n",
        "                                                                                      # def load_and_preprocess_image(path):\n",
        "                                                                                      #   image = tf.read_file(path)\n",
        "                                                                                      #   x_input = preprocess_image( image )\n",
        "                                                                                      #   return preprocess_image(image)\n",
        "\n",
        "\n",
        "                                                                                      # import matplotlib.pyplot as plt\n",
        "\n",
        "                                                                                      # plt.figure(figsize=(8,8))\n",
        "                                                                                      # for n,image in enumerate( train_A_filenames.take(2)):\n",
        "                                                                                      #   plt.subplot(2,2,n+1)\n",
        "                                                                                      #   plt.imshow(image)\n",
        "                                                                                      #   plt.grid(True)\n",
        "                                                                                      #   plt.xticks([])\n",
        "                                                                                      #   plt.yticks([])\n",
        "                                                                                      #   plt.show()\n",
        "\n",
        "                                                                                      # plt.figure( figsize = ( 8, 8 ) )\n",
        "                                                                                      # for n, image in enumerate( train_D_filenames.take( 2 ) ):\n",
        "                                                                                      #   plt.subplot( 2, 2, n+1 )\n",
        "                                                                                      #   plt.imshow( image )\n",
        "                                                                                      #   plt.grid( True )\n",
        "                                                                                      #   plt.xticks( [] )\n",
        "                                                                                      #   plt.yticks( [] )\n",
        "                                                                                      #   plt.show()\n",
        "  \n",
        "time = []\n",
        "timeL = []\n",
        "theta = np.zeros( ( 720, 2 ), dtype = 'float64' )\n",
        "radius = np.zeros( ( 720, 2 ), dtype = 'float64' )\n",
        "annotate_Hour = np.zeros( ( 720, 2 ), dtype = 'float64' )\n",
        "annotate_Min = np.zeros( ( 720, 2 ), dtype = 'float64' )\n",
        "\n",
        "hour = 0.0\n",
        "minute = 0.0\n",
        "\n",
        "#this will read from the csv labels and calculate the appropriate theta\n",
        "#for the minute hand\n",
        "  \n",
        "#this will read the label and calculate the theta for the\n",
        "#hour hand now\n",
        "\n",
        "thetaH = []\n",
        "thetaM = []\n",
        "Hour = []\n",
        "Min = []\n",
        "for i in range( len( train_A_labels ) ):\n",
        "    \n",
        "  time =  train_A_labels[ i ].split( ':' )\n",
        "  hour = int( time[ 0 ] )\n",
        "  minute = int( time[ 1 ] )\n",
        "  if ( time[ 0 ] == '12' ):\n",
        "    hour = 0\n",
        "  annotate_Hour[ i ][ 1 ] = float( 0.5 * minute ) + float( 30 * hour )\n",
        "  annotate_Hour[ i ][ 0 ] = 2\n",
        "  annotate_Min[ i ][ 1 ] = float( 6 * minute )\n",
        "  annotate_Min[ i ][ 0 ] = 4\n",
        "  \n",
        "  \n",
        "  timeL.append( str( time[ 0 ] + time[ 1 ] ) )\n",
        "  \n",
        "  \n",
        "  \n",
        "  X = np.full([100, 100, 1], annotate_Hour[i][1])\n",
        "  X = np.expand_dims(X, axis = 0)\n",
        "  thetaH.append(X)\n",
        "  Z = np.full([100, 100, 1], annotate_Min[i][1])\n",
        "  Z = np.expand_dims(Z, axis = 0)\n",
        "  thetaM.append(Z)\n",
        "thetaH = np.concatenate(thetaH, axis = 0)\n",
        "thetaM = np.concatenate(thetaM, axis = 0)\n",
        "print(thetaH.shape)\n",
        "print(thetaM.shape)\n",
        "\n",
        "\n",
        "#this will stack theta in a 720 x 1 x 2 format\n",
        "#printing output of both theta and radius\n",
        "print( timeL)\n",
        "\n",
        "print( \"Hour annotations: \\n\" )\n",
        "print( annotate_Hour[ :5 ] )\n",
        "print( \"Minute annotations: \\n\" )\n",
        "print( annotate_Min[ :5 ] )\n",
        "  \n",
        "  \n",
        "# time_D = []\n",
        "# timeL_D = []\n",
        "# theta_D = np.zeros( ( 720, 2 ), dtype = 'float64' )\n",
        "# radius_D = np.zeros( ( 720, 2 ), dtype = 'float64' )\n",
        "# annotate_Hour_D = np.zeros( ( 720, 2 ), dtype = 'float64' )\n",
        "# annotate_Min_D = np.zeros( ( 720, 2 ), dtype = 'float64' )\n",
        "\n",
        "# hour_D = 0.0\n",
        "# minute_D = 0.0  \n",
        "  \n",
        "  \n",
        "# thetaH_D = []\n",
        "# thetaM_D = []\n",
        "# Hour_D = []\n",
        "# Min_D = []\n",
        "# for i in range( len( train_D_labels ) ):\n",
        "    \n",
        "#   time_D =  train_D_labels[ i ].split( ':' )\n",
        "#   hour_D = int( time_D[ 0 ] )\n",
        "#   minute_D = int( time_D[ 1 ] )\n",
        "  \n",
        "#   annotate_Hour_D[ i ][ 1 ] = float( 0.5 * minute_D ) + ( 30 * hour_D )\n",
        "#   annotate_Hour_D[ i ][ 0 ] = 2\n",
        "#   annotate_Min_D[ i ][ 1 ] = float( 6 * minute_D )\n",
        "#   annotate_Min_D[ i ][ 0 ] = 4\n",
        "  \n",
        "  \n",
        "#   timeL_D.append( str( time_D[ 0 ] + time_D[ 1 ] ) )\n",
        "  \n",
        "  \n",
        "  \n",
        "#   X_D = np.full([100, 100, 1], annotate_Hour_D[i][1])\n",
        "#   X_D = np.expand_dims(X_D, axis = 0)\n",
        "#   thetaH_D.append(X_D)\n",
        "#   Z_D = np.full([100, 100, 1], annotate_Min_D[i][1])\n",
        "#   Z_D = np.expand_dims(Z_D, axis = 0)\n",
        "#   thetaM_D.append(Z_D)\n",
        "# thetaH_D = np.concatenate(thetaH_D, axis = 0)\n",
        "# thetaM_D = np.concatenate(thetaM_D, axis = 0)\n",
        "# print(thetaH_D.shape)\n",
        "# print(thetaM_D.shape)\n",
        "\n",
        "\n",
        "# #this will stack theta in a 720 x 1 x 2 format\n",
        "# #printing output of both theta and radius\n",
        "# print( timeL_D)\n",
        "\n",
        "# print( \"Hour annotations: \\n\" )\n",
        "# print( annotate_Hour_D[ :5 ] )\n",
        "# print( \"Minute annotations: \\n\" )\n",
        "# print( annotate_Min_D[ :5 ] )  \n",
        "  \n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhzQmuOhZxAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(annotate_Hour[61])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEBXxOf7W0Os",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_dataset = []\n",
        "label_to_index = []\n",
        "list_values = []\n",
        "label_to_index = dict((name, index) for index, name in enumerate(timeL))\n",
        "list_values = [ v for v in label_to_index.values() ]\n",
        "list_values\n",
        "\n",
        "target_dataset = keras.utils.to_categorical(list_values,num_classes = 720)\n",
        "\n",
        "print( target_dataset[:10] )\n",
        "print( target_dataset.shape )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEbwiceGDqQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A_output = []\n",
        "# label_to_index_A = []\n",
        "# list_values_A = []\n",
        "# label_to_index_A = dict((name, index) for index, name in enumerate(timeL))\n",
        "# list_values_A = [ v for v in label_to_index_A.values() ]\n",
        "# list_values_A\n",
        "\n",
        "# A_output = keras.utils.to_categorical(list_values_A,num_classes = 720)\n",
        "\n",
        "# print(A_output.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dkB4hOPDGFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# D_output = []\n",
        "# label_to_index_D = []\n",
        "# list_values_D = []\n",
        "# label_to_index_D = dict((name, index) for index, name in enumerate(timeL_D))\n",
        "# list_values_D = [ v for v in label_to_index_D.values() ]\n",
        "\n",
        "\n",
        "# D_output = keras.utils.to_categorical(list_values_D,num_classes = 720)\n",
        "\n",
        "print(D_output.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JO-qSt3JQIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y_output =[]\n",
        "# y_output = np.concatenate([A_output, D_output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_gPW_MPJcsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_3hm_SMt-Qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#puts everything into a (720, 100, 100, 1) 4d tensor\n",
        "imgs = []\n",
        "for images in image_analog:\n",
        "  img = image.load_img( images, target_size =( 100, 100 ), color_mode = \"grayscale\" )\n",
        "  image_tensor = image.img_to_array( img )\n",
        "  image_tensor = np.expand_dims( image_tensor, axis = 0 )\n",
        "  image_tensor /= 255.0\n",
        "  imgs.append(image_tensor)\n",
        "  \n",
        "imgs = np.concatenate(imgs, axis = 0)\n",
        "print( imgs.shape )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NpvSXnQE9kP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imgs[0,:, : , 0])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYtpO5-KC-Ac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imgs_d = []\n",
        "# for images in image_digital:\n",
        "#   img_d = image.load_img( images, target_size =( 100, 100 ), color_mode = \"grayscale\" )\n",
        "#   image_tensor_d = image.img_to_array( img_d )\n",
        "#   image_tensor_d = np.expand_dims( image_tensor_d, axis = 0 )\n",
        "#   image_tensor_d /= 255.0\n",
        "#   imgs_d.append(image_tensor_d)\n",
        "  \n",
        "# imgs_d = np.concatenate(imgs_d, axis = 0)\n",
        "# print( imgs_d.shape )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9UM5DmLDKR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#show one grayscale image\n",
        "# plt.imshow( imgs_d[1, :, : ,0] )\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTLWX085ueGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#transforms shape to a (720, 100, 100, 3) 4d tensor\n",
        "dataset = []\n",
        "dataset = np.concatenate([imgs, thetaH, thetaM], axis = -1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwTNLF6VKQqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# z_input = []\n",
        "# z_input = np.concatenate([imgs_d, thetaH_D, thetaM_D], axis = -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ-uldwTKeO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(dataset.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7_-eC2OEKEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sanity check of new 4d tensor\n",
        "# print(z_input.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrxSibFNKkj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_input = []\n",
        "# X_input = np.concatenate([x_input, z_input], axis = 0)\n",
        "# print(X_input.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8ErlrIaEWPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#image and 0 - 1 values\n",
        "plt.imshow(x_input[0,:,:,0])\n",
        "plt.show()\n",
        "print(x_input[0,:,:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQr8A2OqBmcs",
        "colab_type": "text"
      },
      "source": [
        "double checking length of the image after the resizing operation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFwBZBxWDhfv",
        "colab_type": "text"
      },
      "source": [
        "visualizing input in an array format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9KXZu5ZB4OI",
        "colab_type": "text"
      },
      "source": [
        "printing length of image d after the resizing operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocZN1E8RBYeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 5\n",
        "num_val_samples = 720 // k\n",
        "num_scores = []\n",
        "\n",
        "for i in range( k ):\n",
        "  print( 'processing fold #', i )\n",
        "  val_data = dataset[ ( i * num_val_samples ) :  (i + 1) * num_val_samples ]\n",
        "  val_targets = target_dataset[ i * num_val_samples: (i + 1) * num_val_samples ]\n",
        "  \n",
        "  partial_train_data = np.concatenate(\n",
        "    [ dataset[ :i * num_val_samples ],\n",
        "     dataset[ ( i + 1 ) * num_val_samples: ] ],\n",
        "    axis = 0 )\n",
        "  \n",
        "  partial_train_targets = np.concatenate(\n",
        "    [ target_dataset[ :i * num_val_samples ],\n",
        "     target_dataset[ ( i + 1 ) * num_val_samples: ] ],\n",
        "    axis = 0 )\n",
        "\n",
        "  \n",
        "x_input = partial_train_data\n",
        "y_output = partial_train_targets\n",
        "x_val = val_data\n",
        "y_val = val_targets\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wn9NDqfXoZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print( \"x_input shape: \", x_input.shape )\n",
        "print( \"y_output shape: \", y_output.shape )\n",
        "print( \"x_val shape: \", x_val.shape )\n",
        "print( \"y_val shape: \", y_val.shape )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn9GZxPeTxJ9",
        "colab_type": "text"
      },
      "source": [
        "using k fold to boost sample as well as slice validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4RUgxODQ6dx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(image_analog)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atjfV07JDRyb",
        "colab_type": "text"
      },
      "source": [
        "This is the k folding snippet we'll use to get our split our training and validation data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaWlpAEP85gK",
        "colab_type": "text"
      },
      "source": [
        "Sanity test for the files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgn0IQGxJLsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def residual_unit( inputs, filters, kernel, drop_out = 0.0, pooling = False ):\n",
        "  res = inputs\n",
        "  \n",
        "  if pooling == True:\n",
        "    res = Conv2D( filters, kernel_size = 1, strides = ( 2, 2) )( res )\n",
        "    inputs = MaxPooling2D( pool_size = ( 2, 2 ) )(inputs)\n",
        "    \n",
        "  inputs = BatchNormalization()( inputs )\n",
        "  inputs = Conv2D( filters, kernel, padding = 'same' )( inputs )\n",
        "  inputs = Activation( \"relu\" )( inputs )\n",
        "  inputs = Dropout( drop_out )( inputs )\n",
        "  \n",
        "  inputs = BatchNormalization()( inputs )\n",
        "  inputs = Conv2D( filters, kernel, padding = 'same' )( inputs )\n",
        "  inputs = Activation( \"relu\" )( inputs )\n",
        "  \n",
        "  inputs = keras.layers.add( [ inputs, res ] )\n",
        "  \n",
        "  return inputs\n",
        "\n",
        "# #main function\n",
        "\n",
        "\n",
        "# #using callback to save a clock AI on best validation.\n",
        "# #model.save('clock_ai_0.1.h5')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7Unkw2yFXpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = Sequential()\n",
        "# model.add( Conv2D( 32, ( 3, 3 ), activation = 'relu', input_shape = x_input[ 0,:,:,:].shape ) )\n",
        "# model.add( Conv2D( 4, ( 3, 3 ), activation = 'relu' ) )\n",
        "# model.add( Flatten() )\n",
        "# model.add( Dense(720, activation = 'softmax') )\n",
        "# model.summary()\n",
        "\n",
        "input_shape = Input( shape = x_input[ 0, :, :, :].shape )\n",
        "\n",
        "inputs = input_shape\n",
        "\n",
        "inputs = Conv2D( 16, 3, padding = 'same' )( inputs )\n",
        "inputs = residual_unit( inputs, 16, 3 )\n",
        "#inputs = residual_unit( inputs, 16, 3 )\n",
        "\n",
        "inputs = residual_unit( inputs, 32, 3, 0.3, True )\n",
        "#inputs = residual_unit( inputs, 32, 3 )\n",
        "\n",
        "inputs = residual_unit( inputs, 64, 3, 0.3, True )\n",
        "#inputs = residual_unit( inputs, 64, 3 )\n",
        "\n",
        "inputs = BatchNormalization()( inputs )\n",
        "inputs = Conv2D( 128, 3 )( inputs )\n",
        "inputs = Activation( \"relu\" )( inputs )\n",
        "\n",
        "inputs = Flatten()( inputs )\n",
        "#inputs = Dense( 50 )( inputs )\n",
        "inputs = Dense( 60 )( inputs )\n",
        "inputs = Dense( 720 )( inputs )\n",
        "prediction = Activation( \"softmax\" )( inputs )\n",
        "model = Model( input_shape, prediction )\n",
        "\n",
        "model.compile(optimizer = 'adam', \n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "history = model.fit( x_input , y_output, epochs=200, batch_size = 75, validation_data = ( x_val, y_val ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U9MjEf-b03-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#first run with no dropout and got a flat validation acc curve. Moved dropout to 30%.\n",
        "#second run, double filter sizes and up batch size to 128 from 100. fell flat no learning\n",
        "#reverted to first filter sizes and dropped to 20% dropout and kept batch size at 128\n",
        "#halved the conv2d layers and lowered batch size to 75. runs faster and train is getting better, val is staying flat.\n",
        "#changed the dropout to 30%. Val_acc is still flat, not gaining.\n",
        "#trying the removal of 3 res_net layers to see if a smaller model works better. Training skyrocketed in acc. Val remains pretty flat still.\n",
        "#removed the 50 filter Dense Layer to see if an even smaller layer will improve training and val acc. Forgot to reset runtimes and train acc hit 100%\n",
        "#reset runtimes and validation is still running flat."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRcCBjD3ZbIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLurvC5Y8sut",
        "colab_type": "text"
      },
      "source": [
        "Gameplan is to use polar coordinates in order to give an additional feature to the learning model during training.\n",
        "\n",
        "Initially considered using pixels to calculate theta since arctan( y / x ) will give us the angle of the clock hand.\n",
        "However, since the pixels were blurry compounded by the fact that the conditions to make theta happen is complex, an alternative was considered.\n",
        "\n",
        "Rather than use X and Y to calculate theta, the idea is then to use degree of 360 and divide by units of 60 ( which represent the minutes ). This gives us 6 degrees of movement per ***\"minute\"***.\n",
        "\n",
        "For the ***\"Hour\"*** hand we know that the hand moves 5 minute units to move to the next hour. 5 * 6 gives us 30 degrees per hour, so if we take 30 degree /60 minutes we get 0.5 degrees/minute.\n",
        "\n",
        "Same idea will be applied to the hour-hand cause this would be the one that gives the model problem since the hour-hand moves as the minute hand moves and makes things a little harder to do for the hour identification.\n",
        "\n",
        "( 4/29/19 )\n",
        "\n",
        "*added k folding so we can get our training and validation split accordingly for the small sample size\n",
        "\n",
        "*added residual unit function which will allow us to make residual units with dropout and pooling capabilities\n",
        "\n",
        "*added annotation function which will generate the other portion of input the network will be using to learn\n",
        "\n",
        "*Data generator has been added but hasn't been customized to work with this problem\n",
        "\n"
      ]
    }
  ]
}